{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Conspiracy Theories\n\nA sample of texts from `r/conspiracy`"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom cytoolz import *\nimport spacy\nimport matplotlib.pyplot  as plt\nimport multiprocessing as mp\n\npd.set_option('display.max_colwidth', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import *\nfrom sklearn.feature_extraction.text import *\nfrom sklearn.feature_extraction import *\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import *\nfrom sklearn.cluster import *\nfrom sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nfrom spacy import displacy\nfrom spacy.tokens import Token\nnlp = spacy.load('en', disable=['ner'])\nfrom spacy.lang.en.stop_words import STOP_WORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/clusterdata/clustering_data.csv\")\ndf = df[df['body'].str.len()>250]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regretfully the parallel method below does not work in Windows."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef tokenize(text):\n    return [tok.lower_ for tok in nlp.tokenizer(text) if (not tok.like_url) and (tok.is_alpha) and not (tok.is_stop)]\n#   \n\nwith mp.Pool() as p:\n    df['tokens'] = p.map(tokenize, df['body'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By the way parentheses in the cell above after `if` are not needed. I added them for easier reading."},{"metadata":{},"cell_type":"markdown","source":"## Adding Negation"},{"metadata":{"trusted":true},"cell_type":"code","source":"Token.set_extension('neg', default=False, force=True)\ndf['doc'] = list(nlp.pipe(df['body']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for doc in df['doc']:\n    for tok in doc:\n        if tok.dep_ == 'neg':\n            tok.head._.neg = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def negtokens(doc):\n    return ['NOT:'+tok.lower_ if tok._.neg else tok.lower_ for tok in doc]\ndf['negtokens'] = df['doc'].apply(negtokens)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make document-term matrix and scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessing = make_pipeline(TfidfVectorizer(analyzer=identity, min_df=3, max_df=0.3, norm='l2', use_idf=True), \n                    TfidfTransformer(norm='l2', use_idf=True)\n                    #, StandardScaler(with_mean=False)\n                    )\nX = preprocessing.fit_transform(df['tokens'])\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Means \nActually `scikit-learn` has a number of clustering methods for different needs.  \nhttps://scikit-learn.org/stable/modules/clustering.html  \nThey provide explanitions which method works in what case and if they work well on big data sets.\n\nUse **k-means** algorithm to group texts into up to 10 clusters and compute **silhoutte** coefficients:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nclusterN=12\n# computing WCSS measure for cluster numbers from 5 to clusterN\nwcss = []\nsilhoutte_score =[]\nfor i in range(5, clusterN+1):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter=500, n_init=20, random_state = 0, n_jobs=4, precompute_distances=True)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    silhoutte_score.append(silhouette_score(X, kmeans.labels_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making a plot for Silhouette scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(5, clusterN+1), silhoutte_score)\nplt.xticks(range(4, clusterN+1), range(4, clusterN+1))\nplt.title('The Silhoutte Score plot')\nplt.xlabel('Number of clusters')\nplt.ylabel('silhoutte_scores')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Making a plot for Elbow method."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(5, clusterN+1), wcss)\nplt.xticks(range(4, clusterN+1), range(4, clusterN+1))\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or it could be computed. The first printed number is the number of preferable clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(wcss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cosines = -1 * np.ones(clusterN-2)\nfor i in range(len(wcss)-1):\n   # check if the point is below a segment midpoint connecting its neighbors\n   if (wcss[i] < (wcss[i+1]+wcss[i-1])/2 ):\n       cosines[i]= (-1+(wcss[i-1]-wcss[i])*(wcss[i+1]-wcss[i]))/ \\\n       ((1+(wcss[i-1]-wcss[i])**2)*(1+ (wcss[i+1]-wcss[i])**2))**.5\n\nprint(np.flip(np.argsort(cosines))+5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Looks like 7 is a good number of clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nkmeans = KMeans(7, n_jobs=-1).fit(X)\ndf['cluster'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['body'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keywords\n\nTo get some insight into what a text cluster represents, we can find its keywords using PMI:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def keywords(cluster, n=12):\n    f = pd.DataFrame({'all': pd.value_counts(list(concat(df['tokens'])))})\n    f['cl'] = pd.value_counts(list(concat(df[df['cluster']==cluster]['tokens'])))\n    f['pmi'] = np.log2( (f['cl'] * np.sum(f['all'])) / \n                        (f['all'] * np.sum(f['cl'])) )\n    return list(f['pmi'][f['all']>25].sort_values(ascending=False)[:n].index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(8):\n    print(i,' '.join(keywords(i)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = kmeans.transform(X)\ndf['body'].iloc[dist[:,5].argsort()[:12]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\n\nfrom spacy.tokens import Token\ndf['doc'] = list(nlp.pipe(df['body']))\n\nToken.set_extension('neg', default=False, force=True)\nfor doc in df['doc']:\n    for tok in doc:\n        if tok.dep_ == 'neg':\n            tok.head._.neg = True","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}