{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Conspiracy Theories\n\nA sample of texts from `r/conspiracy`"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom cytoolz import *\nimport spacy\n\npd.set_option('display.max_colwidth', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import *\nfrom sklearn.feature_extraction import *\nfrom sklearn.decomposition import *\nfrom sklearn.cluster import *\nfrom sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/clusterdata/clustering_data.csv\")\ndf = df[df['body'].str.len()>250]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef tokenize(text):\n    return [tok.lower_ for tok in nlp.tokenizer(text) if not tok.like_url]\ndf['tokens'] = df['body'].apply(tokenize)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make document-term matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = TfidfVectorizer(analyzer=identity, min_df=3, max_df=0.25, norm='l2', use_idf=True) \\\n        .fit_transform(df['tokens'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Means\n\nUse **k-means** algorithm to group texts into 25 clusters and compute **silhoutte** coefficients:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nkmeans = KMeans(25, n_jobs=-1).fit(X)\ndf['cluster'] = kmeans.labels_\ndf['silhouette'] = silhouette_samples(X, df['cluster'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Silhoutte scores compare the distances among texts within a cluster to distances among texts in different clusters.  A 'good' cluster should have a large score:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['silhouette'].mean().sort_values()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of texts in a cluster is also instructive.  Interesting clusters are usually medium-sized. Clusters with only a few texts are picking up noise, and clusters with a large number of texts are probably incoherent."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['body'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keywords\n\nTo get some insight into what a text cluster represents, we can find its keywords using PMI:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def keywords(cluster, n=10):\n    f = pd.DataFrame({'all': pd.value_counts(list(concat(df['tokens'])))})\n    f['cl'] = pd.value_counts(list(concat(df[df['cluster']==cluster]['tokens'])))\n    f['pmi'] = np.log2( (f['cl'] * np.sum(f['all'])) / \n                        (f['all'] * np.sum(f['cl'])) )\n    return list(f['pmi'][f['all']>25].sort_values(ascending=False)[:n].index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(25):\n    print(i,' '.join(keywords(i)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like cluster 11 has something to do with vaccines, but it's hard to tell what they're saying from keywords alone.  So, we can also find some representative texts that are close to the center of the cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = kmeans.transform(X)\ndf['body'].iloc[dist[:,17].argsort()[:20]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's try the same thing, but using glove vectors instead of tfidf:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def vector(text):\n    return nlp(text).vector\ndf['vec'] = df['body'].apply(vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeansv = KMeans(25, n_jobs=-1).fit(X)\ndf['cluster'] = kmeansv.labels_\ndf['silhouette'] = silhouette_samples(X, df['cluster'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['silhouette'].mean().sort_values()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['body'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(25):\n    print(i,' '.join(keywords(i)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The moon landings were faked?!?"},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = kmeansv.transform(X)\ndf['body'].iloc[dist[:,15].argsort()[:20]]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
