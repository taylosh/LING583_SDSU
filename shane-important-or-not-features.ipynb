{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom cytoolz import identity\nimport spacy\nfrom spacy.lang.en import English\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom sklearn.feature_extraction.text import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/newsdata/classification.csv\")\ntest = pd.read_csv(\"../input/newsdata/classification_test.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Importance of features, reducing number of features."},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en', disable=['tagger', 'ner', 'parser'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize(text):\n    return [tok.text for tok in nlp.tokenizer(text.lower()) if (tok.text not in STOP_WORDS) and ((tok.text).isalpha())]\ndf['tokens'] = df['text'].apply(tokenize)\ntest['tokens'] = test['text'].apply(tokenize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtm =  CountVectorizer(analyzer=identity)\ndtm.fit(df['tokens'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dtm.fit_transform(df['tokens'])\nX_test = dtm.transform(test['tokens'])\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I would like a function for error metrics computation, because I will compute different models and want to compare results."},{"metadata":{},"cell_type":"markdown","source":"## Feature Scaling\nScaling push numbers into middle range, somewhere between -4 and 4, most of them not close to 0. These numbers are computed with the most presicion by computers, because truncation errors for very small numbers may accumulate. "},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler(with_mean=False)\nX = sc.fit_transform(X)\nX_test = sc.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Logistic regression\nA logarithmic regression fit a line (plane, hyperplane) between data points. \nIt optimize the following equation:\n$$ \\log\\left(\\frac{odds}{1-odds}\\right) = w_1 x_1+ w_2 x_2 + \\cdots + w_n x_n\n$$\n\nLoss function: $$\\text{Log Loss} = \\sum_{(x,y)\\in D} -y\\log(y') - (1 - y)\\log(1 - y')$$"},{"metadata":{},"cell_type":"markdown","source":"Here we consider so calles Elastic Logarithmic regression, with penalties for I would like to use Penalty l2 means a restriction for coefficient growth. It helps with controlling outlier influence and to avoid overfitting.\n\nPenalty l1 drops useless for prediction variables. Regretfully we do not have explicit information on what variables are dropped.\n\nThe code below takes about 15-16 minutes, and comes with a warning that the process did not converge. We still can use the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nfrom sklearn.linear_model import LogisticRegression\nmodelLG = LogisticRegression(penalty = 'elasticnet', solver ='saga', C=0.2,  l1_ratio =.9, max_iter=200, random_state = 0)\nmodelLG.fit(X, df['sports'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = modelLG.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = modelLG.coef_  # see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\nprint(type(coefficients))\ncoefficients.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dropped_features = (coefficients == 0)[0, :]\nnp.sum(dropped_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_order = dtm.vocabulary_  # see https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\ntype(vocab_order)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in vocab_order:\n    if key[:3]==\"abe\":\n        print(\"For the word '\"+ key + \"' its column number is \", vocab_order[key])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What words were deemed useless?"},{"metadata":{"trusted":true},"cell_type":"code","source":"dropped_features.shape\ndropped_word_indices = np.arange(0, coefficients.shape[1])[dropped_features]\ndropped_word_indices[:33]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndropped_words=[]\nfor key in vocab_order:\n    if int(vocab_order[key]) in dropped_word_indices:\n        dropped_words.append(key)\n\nprint(dropped_words)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest method\n\nThis was quick and with good accuracy."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodelRF = RandomForestClassifier(n_estimators=5000, n_jobs =6)\nmodelRF.fit(X, df['sports'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important_features = modelRF.feature_importances_ # see https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\nimportant_features.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What is the most useful word for Random Forest method?"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.argmax(important_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in vocab_order:\n    if int(vocab_order[key]) == np.argmax(important_features):\n        print(\"The most useful word is '\"+key+\"'.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key in vocab_order:\n    if int(vocab_order[key]) == np.argmin(important_features):\n        print(\"The least useful word is '\"+key+\"'.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"markdown","source":"___\nHere is an alert when your script finished running, where 500 is the frequency in Herz and 2000 is the duration in miliseconds."},{"metadata":{"trusted":true},"cell_type":"code","source":"import winsound\nwinsound.Beep(500, 2000)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}