{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Conspiracy Theories\n\nA sample of texts from `r/conspiracy`"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom cytoolz import *\nimport spacy\nimport matplotlib.pyplot  as plt\nimport multiprocessing as mp\n\npd.set_option('display.max_colwidth', 500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import *\nfrom sklearn.feature_extraction.text import *\nfrom sklearn.feature_extraction import *\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import *\nfrom sklearn.cluster import *\nfrom sklearn.metrics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spacy.lang.en.stop_words import STOP_WORDS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlp = spacy.load('en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/clusterdata/clustering_data.csv\")\ndf = df[df['body'].str.len()>250]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Regretfully the parallel method below does not work in Windows."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndef tokenize(text):\n    return [tok.lower_ for tok in nlp.tokenizer(text) if (not tok.like_url) and (tok.is_alpha)]\n#   and not (tok.is_stop)\n\nwith mp.Pool() as p:\n    df['tokens'] = p.map(tokenize, df['body'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By the way parentheses in the cell above after `if` are not needed. I added them for easier reading."},{"metadata":{},"cell_type":"markdown","source":"## Make document-term matrix and scaling"},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessing = make_pipeline(TfidfVectorizer(analyzer=identity, min_df=3, max_df=0.3, norm='l2', use_idf=True), \n                    TfidfTransformer(norm='l2', use_idf=True)\n                    #, StandardScaler(with_mean=False)\n                    )\nX = preprocessing.fit_transform(df['tokens'])\nX.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Means \nActually `scikit-learn` has a number of clustering methods for different needs.  \nhttps://scikit-learn.org/stable/modules/clustering.html  \nThey provide explanitions which method works in what case and if they work well on big data sets.\n\nUse **k-means** algorithm to group texts into up to 10 clusters and compute **silhoutte** coefficients:"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nclusterN=10\n# computing WCSS measure for cluster numbers from 5 to clusterN\nwcss = []\nsilhoutte_score =[]\nfor i in range(3, clusterN+1):\n    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter=500, n_init=20, random_state = 0, n_jobs=4, precompute_distances=True)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n    silhoutte_score.append(silhouette_score(X, kmeans.labels_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Making a plot for Silhouette scores"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(3, clusterN+1), silhoutte_score)\nplt.xticks(range(2, clusterN+1), range(2, clusterN+1))\nplt.title('The Silhoutte Score plot')\nplt.xlabel('Number of clusters')\nplt.ylabel('silhoutte_scores')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Making a plot for Elbow method."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(3, clusterN+1), wcss)\nplt.xticks(range(2, clusterN+1), range(2, clusterN+1))\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Or it could be computed. The first printed number is the number of preferable clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"cosines = -1 * np.ones(clusterN-2)\nfor i in range(1, clusterN-3):\n   # check if the point is below a segment midpoint connecting its neighbors\n   if (wcss[i] < (wcss[i+1]+wcss[i-1])/2 ):\n       cosines[i]= (-1+(wcss[i-1]-wcss[i])*(wcss[i+1]-wcss[i]))/ \\\n       ((1+(wcss[i-1]-wcss[i])**2)*(1+ (wcss[i+1]-wcss[i])**2))**.5\n\nprint(np.flip(np.argsort(cosines))+3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like 8 is a good number of clusters."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nkmeans = KMeans(8, n_jobs=-1).fit(X)\ndf['cluster'] = kmeans.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('cluster')['body'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keywords\n\nTo get some insight into what a text cluster represents, we can find its keywords using PMI:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def keywords(cluster, n=20):\n    f = pd.DataFrame({'all': pd.value_counts(list(concat(df['tokens'])))})\n    f['cl'] = pd.value_counts(list(concat(df[df['cluster']==cluster]['tokens'])))\n    f['pmi'] = np.log2( (f['cl'] * np.sum(f['all'])) / \n                        (f['all'] * np.sum(f['cl'])) )\n    return list(f['pmi'][f['all']>25].sort_values(ascending=False)[:n].index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(8):\n    print(i,' '.join(keywords(i)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like cluster 2 has something to do with vaccines, but it's hard to tell what they're saying from keywords alone.  So, we can also find some representative texts that are close to the center of the cluster.\nhttps://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = kmeans.transform(X)\ndf['body'].iloc[dist[:,2].argsort()[:20]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For homework do the same thing, but using glove vectors or fastText instead of tfidf like in the previous lesson notebook"},{"metadata":{},"cell_type":"markdown","source":"# Begin Homework: Using Glove Method"},{"metadata":{},"cell_type":"markdown","source":"## Make document-term matrix and scaling:"},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_doc = nlp(df['body'].iloc[0])\nglove_doc.vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['vec'] = df['review_text'].apply(lambda t: nlp(t).vector)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = make_pipeline(CountVectorizer(analyzer=identity), LogisticRegression())\nbaseline.fit(train['tokens'], train['wine_variant'])\nbaseline.score(test['tokens'], test['wine_variant'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LogisticRegression(C=10)\nmodel.fit(list(train['vec']), train['wine_variant'])\nmodel.score(list(test['vec']),test['wine_variant'] )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## K Means"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nkmeans_glove = KMeans(8, n_jobs=-1).fit(Y)\ndf['vec'] = kmeans_glove.labels_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"df.groupby('vec')['body'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Keywords using PMI"},{"metadata":{"trusted":true},"cell_type":"code","source":"def keywords(cluster, n=20):\n    g = pd.DataFrame({'all': pd.value_counts(list(concat(df['tokens'])))})\n    g['cl'] = pd.value_counts(list(concat(df[df['cluster_glove']==cluster]['tokens'])))\n    g['pmi'] = np.log2( (g['cl'] * np.sum(f['all'])) / \n                        (g['all'] * np.sum(f['cl'])) )\n    return list(g['pmi'][g['all']>25].sort_values(ascending=False)[:n].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(8):\n    print(i,' '.join(keywords(i)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dist = kmeans_glove.transform(Y)\ndf['body'].iloc[dist[:,2].argsort()[:20]]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}